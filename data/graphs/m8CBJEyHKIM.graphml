<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd">
  <key id="d11" for="edge" attr.name="type" attr.type="string" />
  <key id="d10" for="edge" attr.name="seq" attr.type="string" />
  <key id="d9" for="edge" attr.name="notes" attr.type="string" />
  <key id="d8" for="edge" attr.name="flow_id" attr.type="long" />
  <key id="d7" for="node" attr.name="notes" attr.type="string" />
  <key id="d6" for="node" attr.name="service" attr.type="string" />
  <key id="d5" for="node" attr.name="name" attr.type="string" />
  <key id="d4" for="graph" attr.name="graph_usable" attr.type="boolean" />
  <key id="d3" for="graph" attr.name="categories" attr.type="string" />
  <key id="d2" for="graph" attr.name="notes" attr.type="string" />
  <key id="d1" for="graph" attr.name="link" attr.type="string" />
  <key id="d0" for="graph" attr.name="name" attr.type="string" />
  <graph edgedefault="directed">
    <node id="0">
      <data key="d5" />
      <data key="d6">UserConsumerMobile</data>
      <data key="d7" />
    </node>
    <node id="1">
      <data key="d5" />
      <data key="d6">NLB</data>
      <data key="d7" />
    </node>
    <node id="2">
      <data key="d5" />
      <data key="d6">CloudWatch</data>
      <data key="d7" />
    </node>
    <node id="3">
      <data key="d5" />
      <data key="d6">Lambda</data>
      <data key="d7">WORKLOAD_PEEK: compute the compute capacity for auto scaling (i.e., how many EC2 instances to launch)</data>
    </node>
    <node id="4">
      <data key="d5" />
      <data key="d6">AutoScaling</data>
      <data key="d7" />
    </node>
    <node id="5">
      <data key="d5" />
      <data key="d6">EC2</data>
      <data key="d7">AUTOSCALE: True
SPOT: True
WORKLOAD_PEEK: spark batch processing to compute gaming ranks</data>
    </node>
    <edge source="0" target="1" id="0">
      <data key="d8">0</data>
      <data key="d9" />
      <data key="d10">0</data>
      <data key="d11">data</data>
    </edge>
    <edge source="1" target="5" id="0">
      <data key="d8">0</data>
      <data key="d9" />
      <data key="d10">1</data>
      <data key="d11">data</data>
    </edge>
    <edge source="1" target="4" id="0">
      <data key="d8">0</data>
      <data key="d9" />
      <data key="d10">1'</data>
      <data key="d11">meta</data>
    </edge>
    <edge source="2" target="3" id="0">
      <data key="d8">1</data>
      <data key="d9" />
      <data key="d10">0</data>
      <data key="d11">data</data>
    </edge>
    <edge source="3" target="4" id="0">
      <data key="d8">1</data>
      <data key="d9" />
      <data key="d10">1</data>
      <data key="d11">meta</data>
    </edge>
    <edge source="4" target="5" id="0">
      <data key="d8">0</data>
      <data key="d9" />
      <data key="d10">1'.0</data>
      <data key="d11">meta</data>
    </edge>
    <edge source="4" target="5" id="1">
      <data key="d8">1</data>
      <data key="d9" />
      <data key="d10">2</data>
      <data key="d11">meta</data>
    </edge>
    <data key="d0">Dream11: Building a Cost Effective Compute Model for Scaling Microservices</data>
    <data key="d1">https://www.youtube.com/watch?v=m8CBJEyHKIM</data>
    <data key="d2">Sports gaming platform. 70M users, 4M daily active users, 2.7M at peak.
Reply on AutoScaling policies to create compute instances (denoted as "ASG", i.e. Auto Scaling Group) both spot and on-demand.
Separate storage and compute. All states are stored in S3 (not not shown in graph!).
The video skips many details.
Future work: use containers and Kubernetes.
It is interesting that the architecture not just uses the service-provide policies to create compute instances, but also uses a Lambda to customize the workload estimation for provision.</data>
    <data key="d3">compute_intensive</data>
    <data key="d4">False</data>
  </graph>
</graphml>
